                                                  HYPERPARAMETER SEARCH
                                              Hyperparameter-db-project-db15
			                    Pallavi Kashyap | INFO6210 | April 24,2019


ABSTRACT
âˆ’	Hyperparameter tuning is choosing a set of optimal hyperparameters for a learning algorithm.  Hyperparameter tuning is critical for building accurate models, yet most researchers use personal experience to specify their range.
            There are two different methods for optimizing hyperparameters:
            Grid Search
            Random Search



INTRODUCTION
This project is to build the database from thousands of public classification and regression dataset using the Distributed Random Forest (DRF), Generalized Linear Model (GLM), Gradient Boosting Machine (GBM) and XGBOOST algorithms. This data will allow us to estimate the relative importance of hyperparameters, appropriate hyperparameter ranges and to build predictive models of hyperparameter values. Out of those thousands, I am only working on one Dataset-Adult.csv from KAGGLE. After finding the Hyperparameters, we are storing the data in the Database for further analysis.

